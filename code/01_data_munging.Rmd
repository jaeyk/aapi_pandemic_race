---
title: "Data analysis"
author: "Jae Yeon Kim"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

# Load packages 

```{r}
if (!require(pacman)) install.packages("pacman")

pacman::p_load(tidyverse, # tidyverse 
               panelr, # panel data analysis
               here, # computational reproducibility 
               glue, # gluing objects and strings 
               tidylog, # logging analysis
               naniar, # missing data 
               zeallot, # multiple assignments 
               readxl)

source(here("functions/utils.r"))
```

# Tidying 

## Load and merge data 

```{r message = FALSE}
# Check the file names
# list.files(here("raw_data"))
w1 <- read_csv(here("raw_data/wave1.csv"))[-c(1:2),]
w2 <- read_csv(here("raw_data/wave2.csv"))[-c(1:2),]
w3 <- readxl::read_xls(here("raw_data/wave3_alt.xls"))[-c(1:2),]
```

```{r message = FALSE}
codebook <- read_csv(here("raw_data/codebook_alt.csv"))

# Check dimensions 
ncol(w1) == nrow(subset(codebook, wave == "w1"))
ncol(w2) == nrow(subset(codebook, wave == "w2"))
ncol(w3) == nrow(subset(codebook, wave == "w3"))
```

```{r}
# make unique variations of drop variable 
codebook$alt_name[grepl("drop", codebook$alt_name)] <- make.unique(codebook$alt_name[grepl("drop", codebook$alt_name)], sep = "_")
```

## Change column names 

```{r message = FALSE}
names(w1) <- subset(codebook, wave == "w1")$alt_name
names(w2) <- subset(codebook, wave == "w2")$alt_name
names(w3) <- subset(codebook, wave == "w3")$alt_name
```

## Drop "drop_" columns 

```{r}
w1 <- w1 %>% select(!contains("drop"))
w2 <- w2 %>% select(!contains("drop"))
w3 <- w3 %>% select(!contains("drop"))
```

## Add missing variables in each wave

```{r}
w1_copy <- w1
w2_copy <- w2
w3_copy <- w3

# Add missing columns between w1 and w2 to w1
w1_copy <- add_miss_cols(w1_copy, w2_copy)
w2_copy <- add_miss_cols(w2_copy, w1_copy)
# Add missing columns between w3 and w2 to w3
w3_copy <- add_miss_cols(w3_copy, w2_copy)
w2_copy <- add_miss_cols(w2_copy, w3_copy)
# Add missing columns between w3 and w1 to w3
w3_copy <- add_miss_cols(w3_copy, w1_copy)
w1_copy <- add_miss_cols(w1_copy, w3_copy)

# Check
sum(is.na(w2_copy$expdiscrim)) == nrow(w2_copy)
sum(is.na(w3_copy$expdiscrim)) == nrow(w3_copy)

w1 <- w1_copy
w2 <- w2_copy
w3 <- w3_copy
```

```{r}
# Check
unique(w1$party.id)
# 1 == Independent 
# 2 == Democrat 
# 3 == Republican
unique(w2$party.id) 
# 1 == Republican 
# 2 == Independent 
# 3 == Democrat 
# 4 == Some other party
# 5 == I don't know 
unique(w3$party.id)
# 1 == Republican 
# 2 == Independent 
# 3 == Democrat 
# 4 == Some other party
# 5 == I don't know 
```

## Add an wave identifier 

```{r}
names(w1) <- glue("W1_{names(w1)}")
names(w2) <- glue("W2_{names(w2)}")
names(w3) <- glue("W3_{names(w3)}")
```

## Merge dataframes 

```{r}
# Inner join
w12 <- inner_join(w1, w2, by = c("W1_respondent.id" = "W2_respondent.id"))

w13 <- inner_join(w1, w3, by = c("W1_pid" = "W3_pid"))

# Rename ID columns 
w12 <- w12 %>%
  rename("id" = "W1_respondent.id") 

w13 <- w13 %>%
  rename("id" = "W1_pid") 

# Remove duplicates 
w12 <- w12[!duplicated(w12$id),]
w13 <- w13[!duplicated(w13$id),]
```

## Calculate attrition rate 

$\textrm{Attrition rate} = \frac{\textrm{# of pre_wave participants} - \textrm{# of post_wave participants}}{\textrm{# pre_wave participants}}$

```{r}
attr_rate <- function(pre, post) {
    out <- (pre - post)/pre 
    round(out, 2)}

glue("The attrition rate between w1 and w2 is: {attr_rate({nrow(w1)}, nrow(w12)) * 100}%")
glue("The attrition rate between w2 and w3 is: {attr_rate(nrow(w12), nrow(w13)) * 100}%")
```

## Find common questions 

```{r}
# Wave 1 and 2
common.q12 <- intersect(extract_name(w12, "W2"), extract_name(w12, "W1"))

long12 <- w12 %>%
  select(matches(common.q12) | id) 

# Wave 1 and 3
common.q13 <- intersect(extract_name(w13, "W3"), extract_name(w13, "W1"))

long13 <- w13 %>%
  select(matches(common.q13) | id) 

long_df <- full_join(w12, w13) %>%
  filter(!is.na(W3_gendiscrim))
```

## Bind by rows 

```{r}
w1 <- long_df %>%
  select(matches("W1")) %>%
  select(!matches("W2|W3"))

names(w1) <- str_replace_all(names(w1), "W1_", "")

w1$wave <- 1

w2 <- long_df %>%
  select(matches("W2")) %>%
  select(!matches("W1|W3"))

names(w2) <- str_replace_all(names(w2), "W2_", "")

w2$wave <- 2

w3 <- long_df %>%
  select(matches("W3")) %>%
  select(!matches("W1|W2"))

names(w3) <- str_replace_all(names(w3), "W3_", "")

w3$wave <- 3

w1$respondent.id <- NULL

binded_df <- bind_rows(w1, w2, w3)
glue("The total # of participatns in each wave in the panel data: {nrow(binded_df)/3}")

# Check
subset(binded_df, wave == 2)$expdiscrim
subset(binded_df, wave == 3)$gendiscrim
```

## Final merging 

```{r}
completed_df <- binded_df %>%
  dplyr::select(!matches("response|respondent|pid"))

# Fill in missing values using the previous wave information

# Target variables
vars <- c("race", "gender", "natorigin", "usborn")

completed_df <- fill(completed_df, race)
completed_df <- fill(completed_df, gender)
completed_df <- fill(completed_df, natorigin)
completed_df <- fill(completed_df, usborn)
```


```{r}
# 3228 obs and 105 variables 
dim(completed_df)

write.csv(completed_df, here("processed_data/panel_data.csv"))
```

# Munging

Make a copy 

```{r}
df <- completed_df
```

## Replace 9999 with NA

```{r}
df <- na_if(df, 9999)
```

## Recode values 

```{r}
df1 <- subset(df, wave == 1) 
df23 <- subset(df, wave != 1)

# Party ID
df1$party.id <- recode_party_w1(df1$party.id)
df23$party.id <- recode_party_w23(df23$party.id)

df <- bind_rows(df1, df23)

# Create dummy variables: gender, usborn
c(df$gender, df$usborn) %<-% map(list(df$gender, df$usborn), recode_dummy)

# Check 
unique(df$party.id) %in% c("Republican", "Independent", "Democrat", NA) == TRUE
```

# Export data 

```{r}
write_csv(df, here("processed_data", "panel_data_cleaned.csv"))
```