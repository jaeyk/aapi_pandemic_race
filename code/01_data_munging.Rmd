---
title: "Data analysis"
author: "Jae Yeon Kim"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

# Load packages 

```{r}
if (!require(pacman)) install.packages("pacman")

pacman::p_load(tidyverse, # tidyverse 
               car, # companion to applied regression  
               here, # computational reproducibility 
               glue, # gluing objects and strings 
               tidylog, # logging analysis
               naniar, # missing data 
               zeallot) # multiple assignments 

source(here("functions/utils.r"))
```

# Load and merge data 

```{r message = FALSE}
# Check the file names
# list.files(here("raw_data"))

w1 <- read_csv(here("raw_data/wave1.csv"))[-c(1:2),]
w2 <- read_csv(here("raw_data/wave2.csv"))[-c(1:2),]
w3 <- read_csv(here("raw_data/wave3.csv"))[-c(1:2),]
codebook <- read_csv(here("raw_data/codebook.csv"))

# make unique variations of drop variable 
codebook$alt_name[grepl("drop", codebook$alt_name)] <- make.unique(codebook$alt_name[grepl("drop", codebook$alt_name)], sep = "_")
```

# Change column names 

```{r message = FALSE}
names(w1) <- subset(codebook, wave == "w1")$alt_name
names(w2) <- subset(codebook, wave == "w2")$alt_name
names(w3) <- subset(codebook, wave == "w3")$alt_name
```

# Drop "drop_" columns 

```{r}
w1 <- w1 %>% select(!contains("drop"))
w2 <- w2 %>% select(!contains("drop"))
w3 <- w3 %>% select(!contains("drop"))
```

# Merge dataframes 

```{r}
w12 <- inner_join(w1, w2, by = c("respondent.id"),
                  suffix = c("_w1", "_w2"))
w13 <- inner_join(w1, w3, by = c("pid"), 
                  suffix = c("_w1", "_w3"))

complete <- left_join(w13, w12)

complete <- complete %>%
  dplyr::select(!matches("response|respondent|pid"))
```

```{r}
write.csv(w12, here("processed_data/w12.csv"))
write.csv(w13, here("processed_data/w13.csv"))
write.csv(complete, here("processed_data/complete.csv"))
```

## Calculate attrition rate 

$\textrm{Attrition rate} = \frac{\textrm{# of pre_wave participants} - \textrm{# of post_wave participants}}{\textrm{# pre_wave participants}}$

```{r}
attr_rate <- function(pre, post) {
    out <- (pre - post)/pre 
    round(out, 2)}

glue("The attrition rate between w1 and w2 is: {attr_rate({nrow(w1)}, nrow(w12)) * 100}%")
glue("The attrition rate between w1 and w3 is: {attr_rate(nrow(w1), nrow(w13)) * 100}%")
```

# Data munging

Make a copy 

```{r}
df <- w123
```

## Replace 9999 with NA

```{r}
round(mean(is.na(df)), 2) # No NA values at this point 

df <- na_if(df, 9999)

# Overall missingness 
round(mean(is.na(df)), 2) # about 13% missing  
```

## Calculate the missingness in the data 

```{r}
# Check the rate of missing variables in the dataset 
map_df(df, ~is.na(.) %>% mean() %>% round(2))

# Visualize missing data 
naniar::vis_miss(df) +
  coord_flip()
```

## Rename columns 

```{r}
df <- df %>%  
    rename_with(~(sub("_", "_q_", .x)), starts_with("W"))

names(df)[str_detect(names(df), "disc")] <- c("W3_disc_covid", "W3_disc_asian", "W2_disc_covid", "W2_disc_asian", "W1_disc_asian", "W1_disc_personal")
```

## Recode values 

```{r}
# Discrimination against Asians
c(df$W2_disc_asian, df$W3_disc_asian) %<-%  map(list(df$W2_disc_asian, df$W3_disc_asian),  recode_response)
```

```{r}
#  Party ID
c(df$W1_q_party, df$W2_q_party, df$W3_q_party) %<-%  map(list(df$W1_q_party, df$W2_q_party, df$W3_q_party),  recode_party)
```

```{r}
# Gender
c(df$W1_q_gender, df$W3_q_gender) %<-%  map(list(df$W1_q_gender, df$W3_q_gender),  recode_dummy)

# US born
c(df$W1_q_usborn, df$W2_q_usborn, df$W3_q_usborn) %<-%  map(list(df$W1_q_usborn, df$W2_q_usborn, df$W3_q_usborn), recode_dummy)
```

## Reshape data 

These variables are included in the data across the waves:

```{r}
reduce(list(extract_name(df, 'W1'), extract_name(df, 'W2'), extract_name(df, 'W3')), intersect)
```

Reshape the data based on these common questions. 

```{r}
df_long <- df %>%
    pivot_longer(
      cols = matches("q_us_born|q_party|disc_asian|q_NatOrigin"), # Choose multiple values using regex 
      names_to = c("wave", ".value"), 
      names_pattern = "(..)_(.*)")
```

```{r}
nrow(df) # the number of observations in the wide data 
nrow(df_long) # the number of observations in the long data 
```

## Save data 

```{r}
save(df, df_long, file = here("processed_data/dfs.Rdata"))
```


